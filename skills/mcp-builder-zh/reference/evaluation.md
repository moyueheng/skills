# MCP 服务器评估指南

## 概述

本文档提供了为 MCP 服务器创建全面评估的指导。评估旨在测试 LLM 是否能够仅使用您提供的工具，有效利用您的 MCP 服务器来回答真实、复杂的问题。

---

## 快速参考

### 评估要求
- 创建 10 个人类可读的问题
- 问题必须是只读的、独立的、非破坏性的
- 每个问题需要多次工具调用（可能需要几十次）
- 答案必须是单个可验证的值
- 答案必须是稳定的（不会随时间变化）

### 输出格式
```xml
<evaluation>
   <qa_pair>
      <question>您的问题</question>
      <answer>单个可验证的答案</answer>
   </qa_pair>
</evaluation>
```

---

## 评估的目的

衡量 MCP 服务器质量的**不是**服务器实现工具的完整性，而是这些实现（输入/输出模式、文档字符串/描述、功能）如何让仅能访问 MCP 服务器的 LLM 能够回答真实且困难的问题。

## 评估概述

创建 10 个只需要只读、独立、非破坏性和幂等操作即可回答的人类可读问题。每个问题应该：
- 真实
- 清晰简洁
- 无歧义
- 复杂，可能需要几十次工具调用或步骤
- 可以用您预先确定的单个可验证值来回答

## 问题指南

### 核心要求

1. **问题必须是独立的**
   - 每个问题不应依赖于任何其他问题的答案
   - 不应假设在处理另一个问题时有先前的写操作

2. **问题必须只要求非破坏性和幂等的工具使用**
   - 不应指示或要求修改状态来获得正确答案

3. **问题必须是真实的、清晰的、简洁的和复杂的**
   - 必须要求另一个 LLM 使用多个（可能是几十个）工具或步骤来回答

### 复杂性和深度

4. **问题必须需要深度探索**
   - 考虑需要多个子问题和顺序工具调用的多跳问题
   - 每一步都应受益于在先前问题中找到的信息

5. **问题可能需要大量分页**
   - 可能需要分页浏览多个结果页面
   - 可能需要查询旧数据（1-2 年前的）来查找小众信息
   - 问题必须是困难的

6. **问题必须需要深入理解**
   - 而不是表面层的知识
   - 可以将复杂的观点作为需要证据的 True/False 问题
   - 可以使用多选题格式，其中 LLM 必须搜索不同的假设

7. **问题不能通过直接的关键字搜索解决**
   - 不要包含目标内容中的特定关键字
   - 使用同义词、相关概念或转述
   - 需要多次搜索、分析多个相关项目、提取上下文，然后推导答案

### 工具测试

8. **问题应该压力测试工具返回值**
   - 可能引发工具返回大型 JSON 对象或列表，让 LLM 不堪重负
   - 应该需要理解多种数据模式：
     - ID 和名称
     - 时间戳和日期时间（月、日、年、秒）
     - 文件 ID、名称、扩展名和 mimetypes
     - URL、GID 等
   - 应该探查工具返回所有有用数据形式的能力

9. **问题应该主要反映真实的人类用例**
   - 在 LLM 辅助下的人类会关心的信息检索任务类型

10. **问题可能需要几十次工具调用**
    - 这会挑战上下文有限的 LLM
    - 鼓励 MCP 服务器工具减少返回的信息

11. **包含歧义问题**
    - 可能是歧义的或需要在调用哪些工具上做出困难决定
    - 迫使 LLM 可能犯错或误解
    - 确保尽管有歧义，仍然有一个单一可验证的答案

### 稳定性

12. **问题必须设计成答案不会改变**
    - 不要问依赖于"当前状态"的动态问题
    - 例如，不要计算：
      - 帖子的反应数量
      - 主题的回复数量
      - 频道中的成员数量

13. **不要让 MCP 服务器限制您创建的问题类型**
    - 创建有挑战性和复杂的问题
    - 有些可能无法使用可用的 MCP 服务器工具解决
    - 问题可能需要特定的输出格式（datetime vs. epoch time, JSON vs. MARKDOWN）
    - 问题可能需要几十次工具调用才能完成

## 答案指南

### 验证

1. **答案必须可以通过直接字符串比较验证**
   - 如果答案可以用多种格式重写，在问题中明确指定输出格式
   - 示例："使用 YYYY/MM/DD。"，"回答 True 或 False。"，"回答 A、B、C 或 D，没有其他内容。"
   - 答案应该是单个可验证的值，例如：
     - 用户 ID、用户名、显示名称、名字、姓氏
     - 频道 ID、频道名称
     - 消息 ID、字符串
     - URL、标题
     - 数量
     - 时间戳、日期时间
     - 布尔值（用于 True/False 问题）
     - 电子邮件地址、电话号码
     - 文件 ID、文件名、文件扩展名
     - 多选题答案
   - 答案不需要特殊格式或复杂的结构化输出
   - 答案将使用直接字符串比较进行验证

### 可读性

2. **答案通常应该首选人类可读格式**
   - 示例：名称、名字、姓氏、日期时间、文件名、消息字符串、URL、是/否、true/false、a/b/c/d
   - 而不是不透明的 ID（虽然 ID 也是可接受的）
   - 绝大多数答案应该是人类可读的

### 稳定性

3. **答案必须是稳定/静止的**
   - 查看旧内容（例如，已结束的对话、已启动的项目、已回答的问题）
   - 基于"已关闭"概念创建问题，这些概念总是返回相同的答案
   - 问题可能要求考虑固定时间窗口以避免非静态答案
   - 依赖不太可能改变的上下文
   - 示例：如果查找论文名称，要足够具体，以免与后来发表的论文混淆

4. **答案必须是清晰和无歧义的**
   - 问题必须设计成有一个单一、清晰的答案
   - 答案可以从使用 MCP 服务器工具中推导出来

### 多样性

5. **答案必须是多样的**
   - 答案应该是各种模式和格式中的单个可验证值
   - 用户概念：用户 ID、用户名、显示名称、名字、姓氏、电子邮件地址、电话号码
   - 频道概念：频道 ID、频道名称、频道主题
   - 消息概念：消息 ID、消息字符串、时间戳、月、日、年

6. **答案不能是复杂结构**
   - 不是值列表
   - 不是复杂对象
   - 不是 ID 或字符串列表
   - 不是自然语言文本
   - 除非答案可以通过直接字符串比较直接验证
   - 并且可以真实地重现
   - LLM 不太可能以任何其他顺序或格式返回相同的列表

## 评估流程

### 步骤 1：文档检查

阅读目标 API 的文档以了解：
- 可用的端点和功能
- 如果存在歧义，从网络获取额外信息
- 尽可能并行化此步骤
- 确保每个子代理只检查文件系统或网络上的文档

### 步骤 2：工具检查

列出 MCP 服务器中可用的工具：
- 直接检查 MCP 服务器
- 了解输入/输出模式、文档字符串和描述
- 在此阶段不要调用工具本身

### 步骤 3：开发理解

重复步骤 1 和 2 直到您有很好的理解：
- 多次迭代
- 思考您想要创建的任务类型
- 完善您的理解
- 在任何阶段都不要阅读 MCP 服务器实现本身的代码
- 使用您的直觉和理解来创建合理、真实但非常有挑战性的任务

### 步骤 4：只读内容检查

了解 API 和工具后，使用 MCP 服务器工具：
- 只使用只读和非破坏性操作检查内容
- 目标：识别特定内容（例如，用户、频道、消息、项目、任务）以创建真实问题
- 不应调用任何修改状态的工具
- 不会阅读 MCP 服务器实现本身的代码
- 与追求独立探索的各个子代理并行化此步骤
- 确保每个子代理只执行只读、非破坏性和幂等操作
- 注意：某些工具可能返回大量数据，导致您超出上下文限制
- 进行增量式、小而目标的工具调用进行探索
- 在所有工具调用请求中，使用 `limit` 参数限制结果（<10）
- 使用分页

### 步骤 5：任务生成

检查内容后，创建 10 个人类可读问题：
- LLM 应该能够使用 MCP 服务器回答这些问题
- 遵循上述所有问题和答案指南

## 输出格式

每个 QA 对由一个问题和一个答案组成。输出应该是具有此结构的 XML 文件：

```xml
<evaluation>
   <qa_pair>
      <question>查找在 2024 年第二季度创建的已完成任务最多的项目。项目名称是什么？</question>
      <answer>网站重新设计</answer>
   </qa_pair>
   <qa_pair>
      <question>搜索标记为"bug"并在 2024 年 3 月关闭的问题。哪个用户关闭了最多的问题？提供他们的用户名。</question>
      <answer>sarah_dev</answer>
   </qa_pair>
   <qa_pair>
      <question>查找修改了 /api 目录中的文件并在 2024 年 1 月 1 日到 1 月 31 日之间合并的拉取请求。有多少不同的贡献者参与了这些 PR？</question>
      <answer>7</answer>
   </qa_pair>
   <qa_pair>
      <question>查找在 2023 年之前创建的 star 最多的仓库。仓库名称是什么？</question>
      <answer>data-pipeline</answer>
   </qa_pair>
</evaluation>
```

## 评估示例

### 好的问题

**示例 1：需要深度探索的多跳问题（GitHub MCP）**
```xml
<qa_pair>
   <question>查找在 2023 年第三季度存档的仓库，该仓库之前是组织中最多分叉的项目。该仓库使用的主要编程语言是什么？</question>
   <answer>Python</answer>
</qa_pair>
```

这个问题好的原因是：
- 需要多次搜索来找到已存档的仓库
- 需要确定哪个在存档前有最多分支
- 需要检查仓库详情以了解语言
- 答案是简单、可验证的值
- 基于历史（已关闭的）数据，不会改变

**示例 2：需要在没有关键字匹配的情况下理解上下文（项目管理 MCP）**
```xml
<qa_pair>
   <question>定位专注于改进客户入职并在 2023 年底完成的倡议。项目主管在完成后创建了回顾文档。当时主管的职位头衔是什么？</question>
   <answer>产品经理</answer>
</qa_pair>
```

这个问题好的原因是：
- 不使用特定项目名称（"专注于改进客户入职的倡议"）
- 需要从特定时间框架查找已完成的项目
- 需要确定项目主管及其角色
- 需要从回顾文档理解上下文
- 答案是人类可读且稳定的
- 基于已完成的工作（不会改变）

**示例 3：需要多个步骤的复杂聚合（问题跟踪器 MCP）**
```xml
<qa_pair>
   <question>在 2024 年 1 月报告的所有标记为关键优先级的错误中，哪个被分配人在 48 小时内解决了最高百分比的分配错误？提供被分配人的用户名。</question>
   <answer>alex_eng</answer>
</qa_pair>
```

这个问题好的原因是：
- 需要按日期、优先级和状态过滤错误
- 需要按被分配人分组并计算解决率
- 需要理解时间戳以确定 48 小时窗口
- 测试分页（可能需要处理许多错误）
- 答案是单个用户名
- 基于特定时间段的历史数据

**示例 4：需要跨多种数据类型综合（CRM MCP）**
```xml
<qa_pair>
   <question>查找在 2023 年第四季度从 Starter 升级到 Enterprise 计划且年度合同价值最高的账户。该账户从事哪个行业？</question>
   <answer>医疗保健</answer>
</qa_pair>
```

这个问题好的原因是：
- 需要了解订阅层级变化
- 需要在特定时间框架识别升级事件
- 需要比较合同价值
- 必须访问账户行业信息
- 答案简单且可验证
- 基于已完成的历史交易

### 差的问题

**示例 1：答案随时间变化**
```xml
<qa_pair>
   <question>当前分配给工程团队有多少个开放问题？</question>
   <answer>47</answer>
</qa_pair>
```

这个问题差的原因是：
- 答案会随着问题的创建、关闭或重新分配而改变
- 不基于稳定/静态数据
- 依赖于动态的"当前状态"

**示例 2：关键字搜索太容易**
```xml
<qa_pair>
   <question>查找标题为"添加身份验证功能"的拉取请求，告诉我谁创建了它。</question>
   <answer>developer123</answer>
</qa_pair>
```

这个问题差的原因是：
- 可以通过对确切标题的直接关键字搜索解决
- 不需要深度探索或理解
- 不需要综合或分析

**示例 3：答案格式歧义**
```xml
<qa_pair>
   <question>列出所有以 Python 为主要语言的仓库。</question>
   <answer>repo1, repo2, repo3, data-pipeline, ml-tools</answer>
</qa_pair>
```

这个问题差的原因是：
- 答案是可能以任何顺序返回的列表
- 难以通过直接字符串比较验证
- LLM 可能以不同格式化（JSON 数组、逗号分隔、换行符分隔）
- 最好询问特定聚合（计数）或最高级（最多 star）

## 验证流程

创建评估后：

1. **检查 XML 文件**以了解模式
2. **加载每个任务指令**，并行使用 MCP 服务器和工具，通过尝试自己解决任务来识别正确答案
3. **标记任何操作**，要求写或破坏性操作
4. **累积所有正确答案**并替换文档中的任何错误答案
5. **删除任何 `<qa_pair>`**，要求写或破坏性操作

记住并行化解决任务以避免超出上下文，然后累积所有答案并在最后对文件进行更改。

## 创建质量评估的提示

1. **在生成任务前仔细思考和计划**
2. **在机会出现时并行化**以加快流程和管理上下文
3. **专注于真实用例**，人类实际想要完成的
4. **创建有挑战性的问题**，测试 MCP 服务器能力的极限
5. **确保稳定性**，使用历史数据和已关闭的概念
6. **验证答案**，通过使用 MCP 服务器工具自己解决问题
7. **迭代和完善**，基于您在过程中学到的

---

# 运行评估

创建评估文件后，您可以使用提供的评估框架来测试您的 MCP 服务器。

## 设置

1. **安装依赖项**

   ```bash
   pip install -r scripts/requirements.txt
   ```

   或手动安装：
   ```bash
   pip install anthropic mcp
   ```

2. **设置 API 密钥**

   ```bash
   export ANTHROPIC_API_KEY=your_api_key_here
   ```

## 评估文件格式

评估文件使用 XML 格式，带有 `<qa_pair>` 元素：

```xml
<evaluation>
   <qa_pair>
      <question>查找在 2024 年第二季度创建的已完成任务最多的项目。项目名称是什么？</question>
      <answer>网站重新设计</answer>
   </qa_pair>
   <qa_pair>
      <question>搜索标记为"bug"并在 2024 年 3 月关闭的问题。哪个用户关闭了最多的问题？提供他们的用户名。</question>
      <answer>sarah_dev</answer>
   </qa_pair>
</evaluation>
```

## 运行评估

评估脚本（`scripts/evaluation.py`）支持三种传输类型：

**重要：**
- **stdio 传输**：评估脚本自动为您启动和管理 MCP 服务器进程。不要手动运行服务器。
- **sse/http 传输**：您必须在运行评估之前单独启动 MCP 服务器。脚本连接到指定 URL 上已运行的服务器。

### 1. 本地 STDIO 服务器

对于本地运行的 MCP 服务器（脚本自动启动服务器）：

```bash
python scripts/evaluation.py \
  -t stdio \
  -c python \
  -a my_mcp_server.py \
  evaluation.xml
```

使用环境变量：
```bash
python scripts/evaluation.py \
  -t stdio \
  -c python \
  -a my_mcp_server.py \
  -e API_KEY=abc123 \
  -e DEBUG=true \
  evaluation.xml
```

### 2. 服务器发送事件 (SSE)

对于基于 SSE 的 MCP 服务器（您必须先启动服务器）：

```bash
python scripts/evaluation.py \
  -t sse \
  -u https://example.com/mcp \
  -H "Authorization: Bearer token123" \
  -H "X-Custom-Header: value" \
  evaluation.xml
```

### 3. HTTP（可流式 HTTP）

对于基于 HTTP 的 MCP 服务器（您必须先启动服务器）：

```bash
python scripts/evaluation.py \
  -t http \
  -u https://example.com/mcp \
  -H "Authorization: Bearer token123" \
  evaluation.xml
```

## 命令行选项

```
usage: evaluation.py [-h] [-t {stdio,sse,http}] [-m MODEL] [-c COMMAND]
                     [-a ARGS [ARGS ...]] [-e ENV [ENV ...]] [-u URL]
                     [-H HEADERS [HEADERS ...]] [-o OUTPUT]
                     eval_file

positional arguments:
  eval_file             评估 XML 文件的路径

optional arguments:
  -h, --help            显示帮助消息
  -t, --transport       传输类型：stdio、sse 或 http（默认：stdio）
  -m, --model           要使用的 Claude 模型（默认：claude-3-7-sonnet-20250219）
  -o, --output          报告的输出文件（默认：打印到 stdout）

stdio 选项:
  -c, --command         运行 MCP 服务器的命令（例如，python、node）
  -a, --args            命令的参数（例如，server.py）
  -e, --env             KEY=VALUE 格式的环境变量

sse/http 选项:
  -u, --url             MCP 服务器 URL
  -H, --header          'Key: Value' 格式的 HTTP 头
```

## 输出

评估脚本生成详细报告，包括：

- **摘要统计**：
  - 准确性（正确/总数）
  - 平均任务持续时间
  - 每个任务的平均工具调用
  - 总工具调用

- **每个任务的结果**：
  - 提示和预期响应
  - 代理的实际响应
  - 答案是否正确（✅/❌）
  - 持续时间和工具调用详情
  - 代理对其方法的总结
  - 代理对工具的反馈

### 将报告保存到文件

```bash
python scripts/evaluation.py \
  -t stdio \
  -c python \
  -a my_server.py \
  -o evaluation_report.md \
  evaluation.xml
```

## 完整示例工作流

以下是创建和运行评估的完整示例：

1. **创建您的评估文件**（`my_evaluation.xml`）：

```xml
<evaluation>
   <qa_pair>
      <question>查找在 2024 年 1 月创建最多问题的用户。他们的用户名是什么？</question>
      <answer>alice_developer</answer>
   </qa_pair>
   <qa_pair>
      <question>在 2024 年第一季度合并的所有拉取请求中，哪个仓库的数量最多？提供仓库名称。</question>
      <answer>backend-api</answer>
   </qa_pair>
   <qa_pair>
      <question>查找在 2023 年 12 月完成且从开始到结束持续时间最长的项目。花了多少天？</question>
      <answer>127</answer>
   </qa_pair>
</evaluation>
```

2. **安装依赖项**：

```bash
pip install -r scripts/requirements.txt
export ANTHROPIC_API_KEY=your_api_key
```

3. **运行评估**：

```bash
python scripts/evaluation.py \
  -t stdio \
  -c python \
  -a github_mcp_server.py \
  -e GITHUB_TOKEN=ghp_xxx \
  -o github_eval_report.md \
  my_evaluation.xml
```

4. **查看报告**在 `github_eval_report.md` 中：
   - 查看哪些问题通过/失败
   - 阅读代理对您工具的反馈
   - 识别改进领域
   - 迭代您的 MCP 服务器设计

## 故障排除

### 连接错误

如果出现连接错误：
- **STDIO**：验证命令和参数是否正确
- **SSE/HTTP**：检查 URL 是否可访问且头是否正确
- 确保任何必需的 API 密钥在环境变量或头中设置

### 低准确性

如果许多评估失败：
- 查看每个任务的代理反馈
- 检查工具描述是否清晰和全面
- 验证输入参数是否记录良好
- 考虑工具是否返回过多或过少的数据
- 确保错误消息是可操作的

### 超时问题

如果任务超时：
- 使用更强大的模型（例如，`claude-3-7-sonnet-20250219`）
- 检查工具是否返回过多数据
- 验证分页是否正常工作
- 考虑简化复杂问题